# SPDX-License-Identifier: LGPL-2.1-or-later
#
# Copyright (C) 2023, Raspberry Pi Ltd
#
%YAML 1.1
---
# Raspberry Pi (VC4 and PiSP) specific vendor controls
vendor: rpi
controls:
  - StatsOutputEnable:
      type: bool
      description: |
        Toggles the Raspberry Pi IPA to output the hardware generated statistics.

        When this control is set to true, the IPA outputs a binary dump of the
        hardware generated statistics through the Request metadata in the
        Bcm2835StatsOutput control.

        \sa Bcm2835StatsOutput

  - Bcm2835StatsOutput:
      type: uint8_t
      size: [n]
      description: |
        Span of the BCM2835 ISP generated statistics for the current frame.

        This is sent in the Request metadata if the StatsOutputEnable is set to
        true.  The statistics struct definition can be found in
        include/linux/bcm2835-isp.h.

        \sa StatsOutputEnable

  - ScalerCrops:
      type: Rectangle
      size: [n]
      description: |
        An array of rectangles, where each singular value has identical functionality
        to the ScalerCrop control. This control allows the Raspberry Pi pipeline
        handler to control individual scaler crops per output stream.

        The order of rectangles passed into the control must match the order of
        streams configured by the application.

        Note that using different crop rectangles for each output stream is only
        applicable on the Pi5/PiSP platform.

        \sa ScalerCrop

  - PispStatsOutput:
      type: uint8_t
      size: [n]
      description: |
        Span of the PiSP Frontend ISP generated statistics for the current
        frame. This is sent in the Request metadata if the StatsOutputEnable is
        set to true. The statistics struct definition can be found in
        https://github.com/raspberrypi/libpisp/blob/main/src/libpisp/frontend/pisp_statistics.h

        \sa StatsOutputEnable

  - CnnOutputTensor:
      type: float
      size: [n]
      description: |
        This control returns a span of floating point values that represent the
        output tensors from a Convolutional Neural Network (CNN). The size and
        format of this array of values is entirely dependent on the neural
        network used, and further post-processing may need to be performed at
        the application level to generate the final desired output. This control
        is agnostic of the hardware or software used to generate the output
        tensors.

        The structure of the span is described by the CnnOutputTensorInfo
        control.

        \sa CnnOutputTensorInfo

  - CnnOutputTensorInfo:
      type: uint8_t
      size: [n]
      description: |
        This control returns the structure of the CnnOutputTensor. This structure
        takes the following form:

        constexpr unsigned int NetworkNameLen = 64;
        constexpr unsigned int MaxNumTensors = 8;
        constexpr unsigned int MaxNumDimensions = 8;

        struct CnnOutputTensorInfo {
          char networkName[NetworkNameLen];
          uint32_t numTensors;
          OutputTensorInfo info[MaxNumTensors];
        };

        with

        struct OutputTensorInfo {
          uint32_t tensorDataNum;
          uint32_t numDimensions;
          uint16_t size[MaxNumDimensions];
        };

        networkName is the name of the CNN used,
        numTensors is the number of output tensors returned,
        tensorDataNum gives the number of elements in each output tensor,
        numDimensions gives the dimensionality of each output tensor,
        size gives the size of each dimension in each output tensor.

        \sa CnnOutputTensor

  - CnnEnableInputTensor:
      type: bool
      description: |
        Boolean to control if the IPA returns the input tensor used by the CNN
        to generate the output tensors via the CnnInputTensor control. Because
        the input tensor may be relatively large, for efficiency reason avoid
        enabling input tensor output unless required for debugging purposes.

        \sa CnnInputTensor

  - CnnInputTensor:
       type: uint8_t
       size: [n]
       description: |
        This control returns a span of uint8_t pixel values that represent the
        input tensor for a Convolutional Neural Network (CNN). The size and
        format of this array of values is entirely dependent on the neural
        network used, and further post-processing (e.g. pixel normalisations) may
        need to be performed at the application level to generate the final input
        image.

        The structure of the span is described by the CnnInputTensorInfo
        control.

        \sa CnnInputTensorInfo

  - CnnInputTensorInfo:
      type: uint8_t
      size: [n]
      description: |
        This control returns the structure of the CnnInputTensor. This structure
        takes the following form:

        constexpr unsigned int NetworkNameLen = 64;

        struct CnnInputTensorInfo {
          char networkName[NetworkNameLen];
          uint32_t width;
          uint32_t height;
          uint32_t numChannels;
        };

        where

        networkName is the name of the CNN used,
        width and height are the input tensor image width and height in pixels,
        numChannels is the number of channels in the input tensor image.

        \sa CnnInputTensor

  - CnnKpiInfo:
      type: int32_t
      size: [2]
      description: |
        This control returns performance metrics for the CNN processing stage.
        Two values are returned in this span, the runtime of the CNN/DNN stage
        and the DSP stage in milliseconds.

  - FrameWallClock:
      type: int64_t
      description: |
        Control that returns the wall clock timestamp of a frame. This
        is the "time since epoch" value obtained from the system, in
        microseconds. This value is likely to be subject to
        significantly more jitter than the recorded SensorTimestamp.

  - SyncMode:
      type: int32_t
      description: |
        Puts the camera system into sync mode, so that frames can be
        temporally synchronised with another camera, either on the same
        device, or on a different one.
      enum:
        - name: SyncModeOff
          value: 0
          description: Sync not in use.
        - name: SyncModeServer
          value: 1
          description: |
            Sync on, act as server. The server broadcasts timing
            messages to any clients that are listening, so that the
            clients can synchronise their camera frames with the
            server's.
        - name: SyncModeClient
          value: 2
          description: |
            Sync on, act as client. A client listens for any server
            messages, and arranges for its camera frames to synchronise
            as closely as possible with the server's. Many clients
            can listen out for the same server.

  - SyncWait:
      type: bool
      description: |
        When using the camera syncrhonisation algorithm, the server
        broadcasts timing information to the client. This also includes
        the time (some number of frames in the future) at which it will
        tell the application running on the server when to start using
        the image frames (the "ready time").

        The client receives the "ready time" from the server, and will
        tell the application on its end to start using the frames at
        this same moment.

        While this control value is true, applications (on both client
        and server) should continue to wait.

        Once this value is false, it means that this is the frame where
        client and server have agreed that it is the first synchronised
        frame that should be used by the application.

  - SyncLag:
      type: int64_t
      description: |
        The lag is the amount of time since the "ready time", at which
        the server and client will signal their controlling applications
        that the frames are now synchronised and should be used.

        Normally, therefore, the value will start negative (the "ready
        time" is in the future), and increase towards zero, before
        becoming positive (the "ready time" has elapsed).

        Servers always report this value; clients will omit this control
        until they have received a message from the server that enables
        them to calculate it.

        Normally there will be just one frame where the lag value is, or
        is very close to, zero - the one for which SyncWait becomes
        false. But note that if frames are being dropped, then the "near
        zero" value, or indeed any other, could be skipped. In these
        cases the lag value allows an application to work out exactly
        what has happened.

        \sa SyncWait
...
